{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sýnidæmi (vika 1)\n",
    "\n",
    "Efni:\n",
    "* Aðferð mesta bratta (gradient descent, GD)\n",
    "* Stochastic gradient descent\n",
    "* Línuleg aðhvarfsgreining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Athugum fyrst lágmörkun á fallinu $$f(\\theta_0,\\theta_1) = 4 \\theta_0^2 - 4 \\theta_0 \\theta_1 + 3 \\theta_1^2$$ með aðferð mesta bratta.\n",
    "\n",
    "Stigullinn er $\\nabla = (8 \\theta_0 - 4 \\theta_1, -4 \\theta_0 + 6 \\theta_1)$. Lággildispunktur er $\\theta^* = (0,0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dt=np.zeros(2) # Define a vector with 2 elements to hold the gradient\n",
    "t=np.array([1,1]) # Initia point\n",
    "alpha=1 # Step length (may need to decrease)\n",
    "maxiter=10\n",
    "\n",
    "for iter in range(0,maxiter):\n",
    "    # Gradient\n",
    "    dt[0] = 8*t[0] - 4*t[1]\n",
    "    dt[1] = -4*t[0] + 6*t[1]\n",
    "    t = t-alpha*dt\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REI602M : Linear regression example (11.1.2019)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load a simple regression dataset from a text file (csv format)\n",
    "# Note: There are many ways to load data from files in Python (csvReader, csvDictReader, Pandas, ...)\n",
    "data=np.genfromtxt('simple_linear.csv', delimiter=',', skip_header=1) # Columns: x, y\n",
    "n=data.shape[0]\n",
    "\n",
    "# Construct data matrix for linear regression\n",
    "# Model: y= θ_0 + θ_1*x_1 + ... + θ_p*x_p\n",
    "y=data[:,-1] # Output variable is in the last column in this case\n",
    "\n",
    "# Append a column of ones to the inputs (intercept term)\n",
    "X=np.c_[np.ones(n), data[:,0:-1]] # Include all columns from 'data' except the last\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=4) # Formatting of output\n",
    "\n",
    "# Visalize data\n",
    "plt.scatter(X[:,1],y)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain exact regression coefficients by solving the normal equations, X'Xθ = X'y\n",
    "theta_ex = np.linalg.solve(X.T.dot(X), X.T.dot(y))\n",
    "print('Exact solution: theta=', theta_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic gradient descent (basic implementation)\n",
    "p=X.shape[1]\n",
    "theta=np.zeros(p)\n",
    "alpha=0.1   # May have to be decreased\n",
    "maxiter=10  # May have to be increased\n",
    "for iter in range(0,maxiter):\n",
    "    i = np.random.randint(n) # Select one training example uniformly at random\n",
    "    error = np.dot(theta,X[i,:]) - y[i]\n",
    "    for j in range(0,p):\n",
    "        theta[j] = theta[j] - alpha*error*X[i,j]\n",
    "print('SGD approximation:', theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visalize data and model predictions\n",
    "plt.scatter(X[:,1],y)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "\n",
    "plt.plot(X[:,1], (theta_ex[0] + theta_ex[1]*X[:,1]),c='r', label='exact')\n",
    "plt.plot(X[:,1], (theta[0] + theta[1]*X[:,1]),c='g', label='SGD')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
